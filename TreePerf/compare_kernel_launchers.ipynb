{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f6aa3-c9bc-40e4-9e0f-e4ec435697af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Trace2Tree.trace_to_tree import TraceToTree\n",
    "from tree_perf import TreePerfAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2124c-1819-4d1a-9b0c-f8837175ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_comparison_with_mapping(name1, df_agg1, name2, df_agg2, mapping, include_counts=False):\n",
    "    \"\"\"\n",
    "    Merges two DataFrames by creating an artificial merge key based on a mapping.\n",
    "    If the name is in the mapping or mapping values, it is replaced by \"key/val\" or \"val/key\".\n",
    "    \"\"\"\n",
    "    # Create bidirectional mapping\n",
    "    reverse_mapping = {v: k for k, v in mapping.items()}\n",
    "    full_mapping = {**mapping, **reverse_mapping}\n",
    "    \n",
    "    # Apply mapping to create the merge key\n",
    "    df_agg1['merge_key'] = df_agg1['name'].apply(\n",
    "        lambda x: f\"{x}/{full_mapping.get(x, x)}\" if x in mapping else x\n",
    "    )\n",
    "    df_agg2['merge_key'] = df_agg2['name'].apply(\n",
    "        lambda x: f\"{full_mapping.get(x, x)}/{x}\" if x in mapping.values() else x\n",
    "    )\n",
    "    \n",
    "    # Merge using the artificial merge_key\n",
    "    merged_df = pd.merge(\n",
    "        df_agg1,\n",
    "        df_agg2,\n",
    "        on='merge_key',\n",
    "        how='inner',\n",
    "        suffixes=(f'_{name1}', f'_{name2}')\n",
    "    )    \n",
    "    # Replace merge_key with original names for clarity\n",
    "    merged_df['name_1'] = merged_df[f'name_{name1}']\n",
    "    merged_df['name_2'] = merged_df[f'name_{name2}']\n",
    "    \n",
    "    # Calculate duration ratio for matched rows\n",
    "    merged_df[f'Kernel Duration (ms) Ratio ({name1}/{name2})'] = (\n",
    "        merged_df[f'total_direct_kernel_time_sum_{name1}'] /\n",
    "        merged_df[f'total_direct_kernel_time_sum_{name2}']\n",
    "    )\n",
    "    \n",
    "    # Rearrange columns\n",
    "    hardware_specific_columns = [\n",
    "        f'total_direct_kernel_time_sum_{name1}', f'total_direct_kernel_time_sum_{name2}',\n",
    "    ]\n",
    "    if include_counts:\n",
    "        hardware_specific_columns.extend([f'Count_{name1}', f'Count_{name2}'])\n",
    "    computed_columns = [\n",
    "        f'Kernel Duration (ms) Ratio ({name1}/{name2})',\n",
    "    ]\n",
    "    columns_to_keep = [f'name_{name1}', f'name_{name2}'] + hardware_specific_columns + computed_columns\n",
    "    \n",
    "    # Select only the necessary columns\n",
    "    final_df = merged_df[columns_to_keep]\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed2613-2f59-4f73-873b-3cf437cfab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/path/to/A_pytorch_profile.json'\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "tree_A = TraceToTree(data['traceEvents'])\n",
    "tree_A.build_tree(add_python_func=False)\n",
    "perf_analyzer_A = TreePerfAnalyzer(tree_A)\n",
    "df_A_kernel_launchers = perf_analyzer_A.get_df_kernel_launchers()\n",
    "df_agg_A_kernel_launchers = perf_analyzer_A.get_df_kernel_launchers_summary(df_A_kernel_launchers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96606e-e59c-4c43-88c2-544daa6cc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/path/to/B_pytorch_profile.json'\n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "events = data['traceEvents']\n",
    "tree_B = TraceToTree(events)\n",
    "tree_B.build_tree(add_python_func=False)\n",
    "perf_analyzer_B = TreePerfAnalyzer(tree_B)\n",
    "df_B_kernel_launchers = perf_analyzer_B.get_df_kernel_launchers()\n",
    "df_agg_B_kernel_launchers = perf_analyzer_B.get_df_kernel_launchers_summary(df_B_kernel_launchers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c98a6a-7e42-4260-a292-7ca04a8432a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mapping = {\n",
    "    \"aten::cudnn_convolution\": \"aten::miopen_convolution\",\n",
    "    \"aten::native_batch_norm_backward\": \"aten::miopen_batch_norm_backward\",\n",
    "    \"aten::native_batch_norm\": \"aten::miopen_batch_norm\",\n",
    "    \"FlashAttnFuncBackward\": \"flash_attn::_flash_attn_backward\",\n",
    "    \"FlashAttnFunc\": \"flash_attn::_flash_attn_forward\"\n",
    "}\n",
    "\n",
    "\n",
    "# Generate the merged comparison\n",
    "df_comparison_agg_kernel_launchers = get_merged_comparison_with_mapping('A', df_agg_A_kernel_launchers,\n",
    "                                                           'B', df_agg_B_kernel_launchers, name_mapping)\n",
    "df_comparison_agg_kernel_launchers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
