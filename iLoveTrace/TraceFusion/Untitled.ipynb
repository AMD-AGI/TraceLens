{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6e3649-5627-4b67-86fe-4a4e50269dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fec1404-6d96-45f6-a717-7acdc98c81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_size(size_in_bytes):\n",
    "    \"\"\"Convert bytes to a human-readable format and return size and unit separately.\"\"\"\n",
    "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if size_in_bytes < 1024:\n",
    "            return round(size_in_bytes, 2), unit\n",
    "        size_in_bytes /= 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5126174-0bc3-4c1c-a502-451a8032f136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 350.5 MB\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/home/ajassani/feb12_2025/iteration_6/rank1_trace.json\"\n",
    "file_size = os.path.getsize(file_path)  # Size in bytes\n",
    "num, unit = convert_size(file_size)\n",
    "print(f\"File size: {num} {unit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2cda0f-698b-417c-a18d-a5d08380c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entries: 1310398\n",
      "Sample Entry: {'ph': 'X', 'cat': 'cpu_op', 'name': 'autograd::engine::evaluate_function: NllLossBackward0', 'pid': 153, 'tid': 930, 'ts': 1425746284084.65, 'dur': 410.825, 'args': {'External id': 8193, 'Record function id': 0, 'Sequence number': 1663, 'Fwd thread id': 1, 'Ev Idx': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Efficiently load large JSON\n",
    "with open(file_path, \"rb\") as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "# Check structure\n",
    "events = data[\"traceEvents\"]\n",
    "print(f\"Total Entries: {len(events)}\")\n",
    "print(\"Sample Entry:\", events[0] if isinstance(events, list) else \"Not a list\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5f1d83-586d-4cc2-9acf-57ad10400224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Largest Fields (Key -> Approx Size in Bytes):\n",
      "args: 291.27 MB\n",
      "name: 119.88 MB\n",
      "cat: 78.66 MB\n",
      "ph: 62.48 MB\n",
      "pid: 34.99 MB\n",
      "tid: 34.89 MB\n",
      "ts: 29.99 MB\n",
      "dur: 27.71 MB\n",
      "bp: 2.26 MB\n",
      "id: 1.74 MB\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "def analyze_memory(data):\n",
    "    field_sizes = defaultdict(int)\n",
    "\n",
    "    for entry in data:\n",
    "        for key, value in entry.items():\n",
    "            field_sizes[key] += sys.getsizeof(value)  # Estimate memory per field\n",
    "\n",
    "    # Sort by memory consumption\n",
    "    sorted_fields = sorted(field_sizes.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_fields\n",
    "\n",
    "# Analyze the largest fields\n",
    "largest_fields = analyze_memory(events)\n",
    "print(\"Top 10 Largest Fields (Key -> Approx Size in Bytes):\")\n",
    "for key, size in largest_fields[:10]:\n",
    "    print(f\"{key}: {size / (1024 * 1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af1f1c00-8275-4d16-8a06-90919c925eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Memory-Consuming Categories:\n",
      "python_function: 375.46 MB\n",
      "ac2g: 22.11 MB\n",
      "cpu_op: 16.82 MB\n",
      "cuda_runtime: 16.13 MB\n",
      "cpu_instant_event: 11.84 MB\n",
      "kernel: 5.81 MB\n",
      "user_annotation: 0.84 MB\n",
      "gpu_user_annotation: 0.44 MB\n",
      "fwdbwd: 0.23 MB\n",
      "gpu_memcpy: 0.17 MB\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Aggregate memory usage by 'cat' field\n",
    "category_memory = defaultdict(int)\n",
    "\n",
    "for event in events:\n",
    "    category = event.get(\"cat\", \"Unknown\")  # Default to \"Unknown\" if 'cat' is missing\n",
    "    category_memory[category] += sys.getsizeof(event)\n",
    "\n",
    "# Sort categories by memory usage\n",
    "sorted_categories = sorted(category_memory.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display top memory-consuming categories\n",
    "print(\"Top Memory-Consuming Categories:\")\n",
    "for cat, size in sorted_categories[:10]:  # Show top 10 categories\n",
    "    print(f\"{cat}: {size / (1024 * 1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc19b36e-9575-4c58-a2bf-273e83283176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None,\n",
       " 'Trace',\n",
       " 'ac2g',\n",
       " 'cpu_instant_event',\n",
       " 'cpu_op',\n",
       " 'cuda_runtime',\n",
       " 'fwdbwd',\n",
       " 'gpu_memcpy',\n",
       " 'gpu_memset',\n",
       " 'gpu_user_annotation',\n",
       " 'kernel',\n",
       " 'python_function',\n",
       " 'user_annotation'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cats = set()\n",
    "for event in events:\n",
    "    unique_cats.add(event.get('cat'))\n",
    "unique_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2107b194-8b1a-40de-a893-143590a1b67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 0, 'args': {'labels': 'CPU'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 0, 'args': {'sort_index': 153}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 0, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 0, 'tid': 0, 'args': {'labels': 'GPU 0'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 0, 'tid': 0, 'args': {'sort_index': 5000000}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 1, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 1, 'tid': 0, 'args': {'labels': 'GPU 1'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 1, 'tid': 0, 'args': {'sort_index': 5000001}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 2, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 2, 'tid': 0, 'args': {'labels': 'GPU 2'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 2, 'tid': 0, 'args': {'sort_index': 5000002}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 3, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 3, 'tid': 0, 'args': {'labels': 'GPU 3'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 3, 'tid': 0, 'args': {'sort_index': 5000003}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 4, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 4, 'tid': 0, 'args': {'labels': 'GPU 4'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 4, 'tid': 0, 'args': {'sort_index': 5000004}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 5, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 5, 'tid': 0, 'args': {'labels': 'GPU 5'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 5, 'tid': 0, 'args': {'sort_index': 5000005}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 6, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 6, 'tid': 0, 'args': {'labels': 'GPU 6'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 6, 'tid': 0, 'args': {'sort_index': 5000006}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 7, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 7, 'tid': 0, 'args': {'labels': 'GPU 7'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 7, 'tid': 0, 'args': {'sort_index': 5000007}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 8, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 8, 'tid': 0, 'args': {'labels': 'GPU 8'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 8, 'tid': 0, 'args': {'sort_index': 5000008}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 9, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 9, 'tid': 0, 'args': {'labels': 'GPU 9'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 9, 'tid': 0, 'args': {'sort_index': 5000009}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 10, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 10, 'tid': 0, 'args': {'labels': 'GPU 10'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 10, 'tid': 0, 'args': {'sort_index': 5000010}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 11, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 11, 'tid': 0, 'args': {'labels': 'GPU 11'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 11, 'tid': 0, 'args': {'sort_index': 5000011}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 12, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 12, 'tid': 0, 'args': {'labels': 'GPU 12'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 12, 'tid': 0, 'args': {'sort_index': 5000012}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 13, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 13, 'tid': 0, 'args': {'labels': 'GPU 13'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 13, 'tid': 0, 'args': {'sort_index': 5000013}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 14, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 14, 'tid': 0, 'args': {'labels': 'GPU 14'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 14, 'tid': 0, 'args': {'sort_index': 5000014}}\n",
      "{'name': 'process_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 15, 'tid': 0, 'args': {'name': 'python'}}\n",
      "{'name': 'process_labels', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 15, 'tid': 0, 'args': {'labels': 'GPU 15'}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 15, 'tid': 0, 'args': {'sort_index': 5000015}}\n",
      "{'name': 'thread_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 0, 'tid': 0, 'args': {'name': 'thread 0 (python)'}}\n",
      "{'name': 'thread_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 0, 'tid': 0, 'args': {'sort_index': 0}}\n",
      "{'name': 'thread_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 3, 'tid': 0, 'args': {'name': 'stream 0 '}}\n",
      "{'name': 'thread_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 3, 'tid': 0, 'args': {'sort_index': 0}}\n",
      "{'name': 'thread_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 3, 'tid': 6, 'args': {'name': 'stream 6 '}}\n",
      "{'name': 'thread_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 3, 'tid': 6, 'args': {'sort_index': 6}}\n",
      "{'name': 'thread_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 3, 'tid': 7, 'args': {'name': 'stream 7 '}}\n",
      "{'name': 'thread_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 3, 'tid': 7, 'args': {'sort_index': 7}}\n",
      "{'name': 'thread_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 915, 'args': {'name': 'thread 915 (python)'}}\n",
      "{'name': 'thread_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 915, 'args': {'sort_index': 915}}\n",
      "{'name': 'thread_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 930, 'args': {'name': 'thread 930 (pt_autograd_1)'}}\n",
      "{'name': 'thread_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 930, 'args': {'sort_index': 930}}\n",
      "{'name': 'thread_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 930, 'args': {'name': 'thread 930 (python)'}}\n",
      "{'name': 'thread_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 930, 'args': {'sort_index': 930}}\n",
      "{'name': 'thread_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 153, 'args': {'name': 'thread 153 (python)'}}\n",
      "{'name': 'thread_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 153, 'args': {'sort_index': 153}}\n",
      "{'name': 'thread_name', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 864, 'args': {'name': 'thread 864 (python)'}}\n",
      "{'name': 'thread_sort_index', 'ph': 'M', 'ts': 1425740863831.302, 'pid': 153, 'tid': 864, 'args': {'sort_index': 864}}\n",
      "{'name': 'process_sort_index', 'ph': 'M', 'ts': 1425740863625.094, 'pid': 'Spans', 'tid': 0, 'args': {'sort_index': 536870912}}\n",
      "{'name': 'Iteration Start: PyTorch Profiler', 'ph': 'i', 's': 'g', 'pid': 'Traces', 'tid': 'Trace PyTorch Profiler', 'ts': 1425740863625.094}\n",
      "{'name': 'Record Window End', 'ph': 'i', 's': 'g', 'pid': '', 'tid': '', 'ts': 1425798934966.523}\n"
     ]
    }
   ],
   "source": [
    "# get example\n",
    "count = 5\n",
    "for event in events:\n",
    "    if event.get('cat') is None:\n",
    "        print(event)\n",
    "        # count -= 1\n",
    "        # if count<0:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37129092-5669-4311-878b-8e6b5267009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get example\n",
    "count = 5\n",
    "for event in events:\n",
    "    if event.get('cat') is None:\n",
    "        print(event)\n",
    "        # count -= 1\n",
    "        # if count<0:\n",
    "        #     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
